#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì—¬ëŸ¬ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¹„êµ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import shutil
import urllib.request
import ssl
from pathlib import Path

# SSL ì¸ì¦ì„œ ë¬¸ì œ í•´ê²°
ssl._create_default_https_context = ssl._create_unverified_context

# í•œêµ­ì–´ ì§€ì›ì´ ì¢‹ì€ ëª¨ë¸ë“¤
MODELS = {
    "paraphrase-multilingual-MiniLM-L12-v2": {
        "repo": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        "description": "ë‹¤êµ­ì–´ ì§€ì›, ê²½ëŸ‰í™”ëœ BERT ê¸°ë°˜ ëª¨ë¸",
        "size": "ì•½ 470MB"
    },
    "distiluse-base-multilingual-cased-v2": {
        "repo": "sentence-transformers/distiluse-base-multilingual-cased-v2", 
        "description": "ë‹¤êµ­ì–´ DistilBERT, ë¹ ë¥¸ ì†ë„",
        "size": "ì•½ 540MB"
    },
    "all-mpnet-base-v2": {
        "repo": "sentence-transformers/all-mpnet-base-v2",
        "description": "MPNet ê¸°ë°˜, ë†’ì€ ì„±ëŠ¥ (ì˜ì–´ ì¤‘ì‹¬)",
        "size": "ì•½ 420MB"
    },
    "ko-sroberta-multitask": {
        "repo": "jhgan/ko-sroberta-multitask",
        "description": "í•œêµ­ì–´ íŠ¹í™” RoBERTa",
        "size": "ì•½ 450MB"
    },
    "multilingual-e5-small": {
        "repo": "intfloat/multilingual-e5-small", 
        "description": "ìµœì‹  E5 ë‹¤êµ­ì–´ ëª¨ë¸, ì‘ì€ í¬ê¸°",
        "size": "ì•½ 470MB"
    }
}

def download_model(model_name, repo_id):
    """
    ê°œë³„ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    """
    try:
        print(f"\nğŸ”„ {model_name} ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        print(f"   ğŸ“¦ {MODELS[model_name]['description']}")
        print(f"   ğŸ’¾ í¬ê¸°: {MODELS[model_name]['size']}")
        
        model_dir = f"models/{model_name}"
        
        # ê¸°ì¡´ í´ë”ê°€ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
        if os.path.exists(model_dir) and os.path.exists(f"{model_dir}/pytorch_model.bin"):
            print(f"   âœ… ì´ë¯¸ ë‹¤ìš´ë¡œë“œë¨: {model_dir}")
            return model_dir
        
        # í´ë” ìƒì„±
        os.makedirs(model_dir, exist_ok=True)
        
        # í•„ìˆ˜ íŒŒì¼ë“¤
        base_url = f"https://huggingface.co/{repo_id}/resolve/main"
        
        files = [
            "config.json",
            "pytorch_model.bin",
            "tokenizer.json", 
            "tokenizer_config.json",
            "special_tokens_map.json"
        ]
        
        # sentence-transformers ì „ìš© íŒŒì¼ë“¤
        if "sentence-transformers/" in repo_id:
            files.extend([
                "sentence_bert_config.json",
                "modules.json"
            ])
        
        success_count = 0
        for filename in files:
            try:
                url = f"{base_url}/{filename}"
                filepath = f"{model_dir}/{filename}"
                
                urllib.request.urlretrieve(url, filepath)
                success_count += 1
                
            except Exception as e:
                print(f"   âš ï¸  {filename} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue
        
        if success_count >= 3:  # ìµœì†Œ 3ê°œ íŒŒì¼ì´ ì„±ê³µí•˜ë©´ OK
            print(f"   âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {model_dir} ({success_count}/{len(files)} íŒŒì¼)")
            return model_dir
        else:
            print(f"   âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: í•„ìˆ˜ íŒŒì¼ ë¶€ì¡±")
            return None
            
    except Exception as e:
        print(f"   âŒ {model_name} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def download_all_models():
    """
    ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    """
    print("ğŸš€ ì—¬ëŸ¬ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("=" * 60)
    
    downloaded_models = []
    
    for model_name, info in MODELS.items():
        model_path = download_model(model_name, info["repo"])
        if model_path:
            downloaded_models.append((model_name, model_path))
    
    print("\n" + "=" * 60)
    print("ğŸ“Š ë‹¤ìš´ë¡œë“œ ê²°ê³¼:")
    print(f"âœ… ì„±ê³µ: {len(downloaded_models)}ê°œ ëª¨ë¸")
    print(f"âŒ ì‹¤íŒ¨: {len(MODELS) - len(downloaded_models)}ê°œ ëª¨ë¸")
    
    if downloaded_models:
        print("\nğŸ“‚ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ë“¤:")
        for model_name, model_path in downloaded_models:
            print(f"   â€¢ {model_name}: {model_path}")
    
    return downloaded_models

def create_model_comparison_script():
    """
    ëª¨ë¸ ë¹„êµ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    """
    script_content = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ìŠ¤í¬ë¦½íŠ¸
"""

import json
import os
import time
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def load_data():
    """JSON ë°ì´í„° ë¡œë“œ"""
    with open('ia-data.json', 'r', encoding='utf-8') as f:
        return json.load(f)

def test_model(model_path, model_name, test_queries):
    """ê°œë³„ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    try:
        print(f"\\nğŸ” {model_name} í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        # ëª¨ë¸ ë¡œë“œ
        start_time = time.time()
        model = SentenceTransformer(model_path)
        load_time = time.time() - start_time
        
        # ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
        sample_texts = [
            "ì¹´ë“œ ì´ìš©ë‚´ì—­ ì¡°íšŒ",
            "í¬ì¸íŠ¸ ì ë¦½ í™•ì¸", 
            "ê²°ì œ ë‚´ì—­ ì¡°íšŒ",
            "ì¹´ë“œ ë°œê¸‰ ì‹ ì²­",
            "ë¡œê·¸ì¸ ì¸ì¦"
        ]
        
        # ì„ë² ë”© ìƒì„± ì‹œê°„ ì¸¡ì •
        start_time = time.time()
        embeddings = model.encode(sample_texts)
        embed_time = time.time() - start_time
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤ì— ëŒ€í•œ ê²€ìƒ‰ ì„±ëŠ¥
        results = {}
        for query in test_queries:
            query_emb = model.encode([query])
            similarities = cosine_similarity(query_emb, embeddings)[0]
            max_sim = float(np.max(similarities))
            results[query] = max_sim
        
        return {
            "model_name": model_name,
            "load_time": load_time,
            "embed_time": embed_time,
            "avg_similarity": np.mean(list(results.values())),
            "results": results
        }
        
    except Exception as e:
        print(f"   âŒ {model_name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return None

def compare_models():
    """ëª¨ë“  ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ"""
    print("ğŸ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "ì¹´ë“œ ì´ìš©ë‚´ì—­",
        "í¬ì¸íŠ¸ ì¡°íšŒ", 
        "ê²°ì œ í™•ì¸",
        "ë¡œê·¸ì¸",
        "íšŒì›ê°€ì…"
    ]
    
    # ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ë“¤ ì°¾ê¸°
    model_dirs = []
    if os.path.exists("models"):
        for item in os.listdir("models"):
            model_path = f"models/{item}"
            if os.path.isdir(model_path) and os.path.exists(f"{model_path}/pytorch_model.bin"):
                model_dirs.append((item, model_path))
    
    # ê¸°ì¡´ manual_modelë„ í¬í•¨
    if os.path.exists("manual_model/pytorch_model.bin"):
        model_dirs.append(("manual_model", "manual_model"))
    
    if not model_dirs:
        print("âŒ í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“Š ì´ {len(model_dirs)}ê°œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤...")
    
    results = []
    for model_name, model_path in model_dirs:
        result = test_model(model_path, model_name, test_queries)
        if result:
            results.append(result)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\\n" + "=" * 80)
    print("ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
    print("=" * 80)
    
    # ì •ë ¬ (í‰ê·  ìœ ì‚¬ë„ ê¸°ì¤€)
    results.sort(key=lambda x: x["avg_similarity"], reverse=True)
    
    for i, result in enumerate(results, 1):
        print(f"\\nğŸ† {i}ìœ„: {result['model_name']}")
        print(f"   âš¡ ë¡œë“œ ì‹œê°„: {result['load_time']:.2f}ì´ˆ")
        print(f"   ğŸ”„ ì„ë² ë”© ì‹œê°„: {result['embed_time']:.3f}ì´ˆ")
        print(f"   ğŸ“Š í‰ê·  ìœ ì‚¬ë„: {result['avg_similarity']:.4f}")
        print("   ğŸ” ì¿¼ë¦¬ë³„ ê²°ê³¼:")
        for query, sim in result['results'].items():
            print(f"      â€¢ {query}: {sim:.4f}")

if __name__ == "__main__":
    compare_models()
'''
    
    with open("compare_models.py", "w", encoding="utf-8") as f:
        f.write(script_content)
    
    print("âœ… ëª¨ë¸ ë¹„êµ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ: compare_models.py")

def main():
    print("ğŸ¯ ë‹¤ì¤‘ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë„êµ¬")
    print("=" * 60)
    
    print("ğŸ“‹ ë‹¤ìš´ë¡œë“œí•  ëª¨ë¸ ëª©ë¡:")
    for i, (name, info) in enumerate(MODELS.items(), 1):
        print(f"{i}. {name}")
        print(f"   ğŸ“ {info['description']}")
        print(f"   ğŸ’¾ {info['size']}")
        print()
    
    response = input("ëª¨ë“  ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower()
    
    if response == 'y':
        downloaded_models = download_all_models()
        
        if downloaded_models:
            create_model_comparison_script()
            print("\nğŸ‰ ì™„ë£Œ!")
            print("ğŸ’¡ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ëª¨ë¸ë“¤ì„ ë¹„êµí•´ë³´ì„¸ìš”:")
            print("   python3 compare_models.py")
    else:
        print("âŒ ë‹¤ìš´ë¡œë“œë¥¼ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 