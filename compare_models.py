#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ìŠ¤í¬ë¦½íŠ¸
"""

import json
import os
import time
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def load_data():
    """JSON ë°ì´í„° ë¡œë“œ"""
    with open('ia-data.json', 'r', encoding='utf-8') as f:
        return json.load(f)

def test_model(model_path, model_name, test_queries):
    """ê°œë³„ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    try:
        print(f"\nğŸ” {model_name} í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        # ëª¨ë¸ ë¡œë“œ
        start_time = time.time()
        model = SentenceTransformer(model_path)
        load_time = time.time() - start_time
        
        # ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
        sample_texts = [
            "ì¹´ë“œ ì´ìš©ë‚´ì—­ ì¡°íšŒ",
            "í¬ì¸íŠ¸ ì ë¦½ í™•ì¸", 
            "ê²°ì œ ë‚´ì—­ ì¡°íšŒ",
            "ì¹´ë“œ ë°œê¸‰ ì‹ ì²­",
            "ë¡œê·¸ì¸ ì¸ì¦"
        ]
        
        # ì„ë² ë”© ìƒì„± ì‹œê°„ ì¸¡ì •
        start_time = time.time()
        embeddings = model.encode(sample_texts)
        embed_time = time.time() - start_time
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤ì— ëŒ€í•œ ê²€ìƒ‰ ì„±ëŠ¥
        results = {}
        for query in test_queries:
            query_emb = model.encode([query])
            similarities = cosine_similarity(query_emb, embeddings)[0]
            max_sim = float(np.max(similarities))
            results[query] = max_sim
        
        return {
            "model_name": model_name,
            "load_time": load_time,
            "embed_time": embed_time,
            "avg_similarity": np.mean(list(results.values())),
            "results": results
        }
        
    except Exception as e:
        print(f"   âŒ {model_name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return None

def compare_models():
    """ëª¨ë“  ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ"""
    print("ğŸ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "ì¹´ë“œ ì´ìš©ë‚´ì—­",
        "í¬ì¸íŠ¸ ì¡°íšŒ", 
        "ê²°ì œ í™•ì¸",
        "ë¡œê·¸ì¸",
        "íšŒì›ê°€ì…"
    ]
    
    # ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ë“¤ ì°¾ê¸°
    model_dirs = []
    if os.path.exists("models"):
        for item in os.listdir("models"):
            model_path = f"models/{item}"
            if os.path.isdir(model_path) and os.path.exists(f"{model_path}/pytorch_model.bin"):
                model_dirs.append((item, model_path))
    
    # ê¸°ì¡´ manual_modelë„ í¬í•¨
    if os.path.exists("manual_model/pytorch_model.bin"):
        model_dirs.append(("manual_model", "manual_model"))
    
    if not model_dirs:
        print("âŒ í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“Š ì´ {len(model_dirs)}ê°œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤...")
    
    results = []
    for model_name, model_path in model_dirs:
        result = test_model(model_path, model_name, test_queries)
        if result:
            results.append(result)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 80)
    print("ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
    print("=" * 80)
    
    # ì •ë ¬ (í‰ê·  ìœ ì‚¬ë„ ê¸°ì¤€)
    results.sort(key=lambda x: x["avg_similarity"], reverse=True)
    
    for i, result in enumerate(results, 1):
        print(f"\nğŸ† {i}ìœ„: {result['model_name']}")
        print(f"   âš¡ ë¡œë“œ ì‹œê°„: {result['load_time']:.2f}ì´ˆ")
        print(f"   ğŸ”„ ì„ë² ë”© ì‹œê°„: {result['embed_time']:.3f}ì´ˆ")
        print(f"   ğŸ“Š í‰ê·  ìœ ì‚¬ë„: {result['avg_similarity']:.4f}")
        print("   ğŸ” ì¿¼ë¦¬ë³„ ê²°ê³¼:")
        for query, sim in result['results'].items():
            print(f"      â€¢ {query}: {sim:.4f}")

if __name__ == "__main__":
    compare_models()
